# FraudeXAI
Sistema Inteligente de Detecci√≥n de Fraude en Tiempo Real con An√°lisis Explicable

# Sistema Inteligente de Detecci√≥n de Fraude en Tiempo Real con An√°lisis Explicable

## üìã Descripci√≥n del Proyecto

Sistema end-to-end de detecci√≥n de fraude en transacciones financieras que combina m√∫ltiples algoritmos de Machine Learning y Deep Learning con capacidades de explicabilidad (XAI). El sistema procesa transacciones en tiempo real, identifica patrones fraudulentos y proporciona explicaciones interpretables sobre cada predicci√≥n, cumpliendo con requisitos regulatorios de instituciones financieras.

## üéØ Objetivos

### Objetivo General
Desarrollar un sistema de detecci√≥n de fraude escalable y explicable que demuestre competencias avanzadas en IA, ingenier√≠a de software y arquitectura full-stack, aplicando conocimientos de maestr√≠a en escenarios productivos del mundo real.

### Objetivos Espec√≠ficos

1. **Implementar ensemble de modelos de IA** que combine t√©cnicas supervisadas, no supervisadas y de deep learning para maximizar la detecci√≥n de fraude
2. **Desarrollar pipeline de explicabilidad (XAI)** utilizando SHAP y LIME para proporcionar justificaciones interpretables de cada predicci√≥n
3. **Construir API RESTful de alto rendimiento** con FastAPI que soporte procesamiento en tiempo real con latencias <100ms
4. **Crear dashboard interactivo** para monitoreo de transacciones, visualizaci√≥n de explicaciones y an√°lisis de m√©tricas del modelo
5. **Implementar arquitectura de microservicios** con Docker, CI/CD y testing automatizado que refleje est√°ndares de la industria

## ‚ú® Caracter√≠sticas Principales

### Detecci√≥n de Fraude Multicapa
- **Ensemble de 4 modelos**: Isolation Forest, XGBoost, Autoencoder y LSTM
- **Votaci√≥n ponderada**: Combinaci√≥n de predicciones con pesos optimizados
- **Manejo de desbalance**: SMOTE, class weighting y threshold optimization
- **Feature engineering autom√°tico**: 50+ caracter√≠sticas derivadas de datos raw

### Explicabilidad (XAI)
- **SHAP values**: Contribuci√≥n de cada feature a la predicci√≥n
- **LIME**: Explicaciones locales interpretables
- **Feature importance**: Ranking visual de caracter√≠sticas cr√≠ticas
- **Confidence scores**: Nivel de certeza por predicci√≥n

### Monitoreo en Tiempo Real
- **WebSockets**: Alertas instant√°neas de transacciones sospechosas
- **Dashboard interactivo**: Visualizaci√≥n de m√©tricas en tiempo real
- **Hist√≥rico de alertas**: An√°lisis retroactivo con filtros avanzados
- **Detecci√≥n de drift**: Monitoreo de degradaci√≥n del modelo

### An√°lisis y Reportes
- **M√©tricas de performance**: Precision, Recall, F1-Score, AUC-ROC
- **An√°lisis de falsos positivos/negativos**: Identificaci√≥n de patrones de error
- **Estad√≠sticas de fraude**: Tendencias temporales y por categor√≠a
- **Exportaci√≥n de reportes**: CSV, JSON, PDF

## üõ†Ô∏è Stack Tecnol√≥gico

### Backend

| Tecnolog√≠a | Versi√≥n | Prop√≥sito |
|------------|---------|-----------|
| Python | 3.11+ | Lenguaje principal |
| FastAPI | 0.110+ | Framework API REST |
| SQLAlchemy | 2.0+ | ORM para base de datos |
| Pydantic | 2.6+ | Validaci√≥n de datos |
| PyTorch | 2.2+ | Deep Learning (LSTM, Autoencoder) |
| Scikit-learn | 1.4+ | ML tradicional (Isolation Forest) |
| XGBoost | 2.0+ | Gradient Boosting |
| SHAP | 0.44+ | Explicabilidad de modelos |
| LIME | 0.2+ | Explicaciones locales |
| Pandas | 2.2+ | Manipulaci√≥n de datos |
| NumPy | 1.26+ | Computaci√≥n num√©rica |
| MLflow | 2.10+ | Tracking de experimentos |
| Uvicorn | 0.27+ | ASGI server |

### Frontend

| Tecnolog√≠a | Versi√≥n | Prop√≥sito |
|------------|---------|-----------|
| React | 18.2+ | Framework UI |
| TypeScript | 5.3+ | Type safety |
| Vite | 5.0+ | Build tool |
| Tailwind CSS | 3.4+ | Styling |
| Shadcn UI | Latest | Componentes UI |
| Recharts | 2.10+ | Visualizaciones |
| React Query | 5.17+ | Estado del servidor |
| Axios | 1.6+ | Cliente HTTP |
| Socket.io Client | 4.6+ | WebSockets |

### Base de Datos

| Tecnolog√≠a | Uso |
|------------|-----|
| SQLite | Desarrollo y demo |
| PostgreSQL | Producci√≥n (migraci√≥n futura) |
| Redis | Cach√© (opcional) |

### DevOps

| Tecnolog√≠a | Prop√≥sito |
|------------|-----------|
| Docker | Containerizaci√≥n |
| Docker Compose | Orquestaci√≥n local |
| GitHub Actions | CI/CD pipeline |
| pytest | Testing backend |
| Jest | Testing frontend |
| pre-commit | Git hooks |
| Black | Code formatting |
| Ruff | Linting |

## üèóÔ∏è Arquitectura del Sistema

### Diagrama de Componentes
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         FRONTEND                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ Dashboard  ‚îÇ  ‚îÇ Monitoring ‚îÇ  ‚îÇ  Explainability ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ            ‚îÇ  ‚îÇ            ‚îÇ  ‚îÇ    Viewer       ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ REST API / WebSockets
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      FASTAPI BACKEND                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ              API ROUTES LAYER                        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  /predict  /transactions  /analytics  /explain       ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ            BUSINESS LOGIC LAYER                      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ FraudDetectionService                             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ ExplainabilityService                             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ FeatureEngineeringService                         ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ              ML MODELS LAYER                         ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇIsolation ‚îÇ ‚îÇ XGBoost  ‚îÇ ‚îÇ  LSTM    ‚îÇ ‚îÇAutoencd‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Forest  ‚îÇ ‚îÇClassifier‚îÇ ‚îÇ Network  ‚îÇ ‚îÇ  -er   ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ              Ensemble Voting System                  ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ          EXPLAINABILITY LAYER                        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ          ‚Ä¢ SHAP Calculator                           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ          ‚Ä¢ LIME Explainer                            ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    DATA LAYER                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ   SQLite     ‚îÇ  ‚îÇ  MLflow      ‚îÇ  ‚îÇ    Cache     ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ (Desarrollo) ‚îÇ  ‚îÇ  Tracking    ‚îÇ  ‚îÇ   (Redis)    ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Flujo de Predicci√≥n
```
1. Cliente env√≠a transacci√≥n ‚Üí FastAPI endpoint
2. Feature Engineering: Extracci√≥n de 50+ caracter√≠sticas
3. Preprocesamiento: Normalizaci√≥n y encoding
4. Predicci√≥n Ensemble:
   ‚îú‚îÄ‚îÄ Isolation Forest ‚Üí Score anomal√≠a
   ‚îú‚îÄ‚îÄ XGBoost ‚Üí Probabilidad fraude
   ‚îú‚îÄ‚îÄ Autoencoder ‚Üí Reconstruction error
   ‚îî‚îÄ‚îÄ LSTM ‚Üí Score secuencial
5. Votaci√≥n ponderada ‚Üí Predicci√≥n final
6. Explicabilidad:
   ‚îú‚îÄ‚îÄ SHAP values calculados
   ‚îî‚îÄ‚îÄ LIME explanation generada
7. Almacenamiento en BD
8. Respuesta al cliente + alerta WebSocket (si es fraude)
```

## ü§ñ Modelos de Inteligencia Artificial

### 1. Isolation Forest (Detecci√≥n de Anomal√≠as No Supervisada)
**Prop√≥sito**: Identificar transacciones at√≠picas sin etiquetas previas

**Caracter√≠sticas**:
- Algoritmo basado en √°rboles de decisi√≥n
- Excelente para detectar outliers multivariados
- No requiere datos balanceados
- R√°pido para inferencia

**Hiperpar√°metros clave**:
- `n_estimators`: 150
- `contamination`: 0.002 (basado en tasa real de fraude)
- `max_samples`: 512

### 2. XGBoost Classifier (Clasificaci√≥n Supervisada)
**Prop√≥sito**: Modelo principal de clasificaci√≥n binaria (fraude/leg√≠timo)

**Caracter√≠sticas**:
- Gradient Boosting de alto rendimiento
- Maneja datos desbalanceados con `scale_pos_weight`
- Feature importance nativo
- Regularizaci√≥n L1/L2

**Hiperpar√°metros optimizados**:
- `max_depth`: 6
- `learning_rate`: 0.05
- `n_estimators`: 300
- `scale_pos_weight`: 577 (ratio de desbalance)
- `subsample`: 0.8

### 3. Autoencoder (Deep Learning para Anomal√≠as)
**Prop√≥sito**: Reconstruir transacciones leg√≠timas; alto error ‚Üí fraude

**Arquitectura**:
```
Encoder:
  Input(50) ‚Üí Dense(32, ReLU) ‚Üí Dropout(0.2) ‚Üí 
  Dense(16, ReLU) ‚Üí Latent(8)

Decoder:
  Latent(8) ‚Üí Dense(16, ReLU) ‚Üí Dropout(0.2) ‚Üí 
  Dense(32, ReLU) ‚Üí Output(50, Sigmoid)
```

**Training**:
- Solo datos leg√≠timos (clase negativa)
- Loss: MSE
- Optimizer: Adam (lr=0.001)
- Epochs: 100 con early stopping

### 4. LSTM (An√°lisis Secuencial)
**Prop√≥sito**: Detectar patrones fraudulentos en secuencias de transacciones

**Arquitectura**:
```
Input(sequence_length=10, features=50) ‚Üí
LSTM(64, return_sequences=True) ‚Üí Dropout(0.3) ‚Üí
LSTM(32) ‚Üí Dropout(0.3) ‚Üí
Dense(16, ReLU) ‚Üí Dense(1, Sigmoid)
```

**Features temporales**:
- Ventanas deslizantes de 10 transacciones
- Agregaciones: velocidad, frecuencia, monto promedio
- Gaps temporales entre transacciones

### Ensemble Strategy

**Votaci√≥n Ponderada**:
```python
final_prediction = (
    0.15 * isolation_forest_score +
    0.45 * xgboost_probability +
    0.25 * autoencoder_anomaly_score +
    0.15 * lstm_probability
)

threshold = 0.5  # Optimizado con curva ROC
is_fraud = final_prediction > threshold
```

**Pesos justificados**:
- XGBoost (45%): Mayor precisi√≥n en validaci√≥n
- Autoencoder (25%): Fuerte en anomal√≠as nuevas
- Isolation Forest (15%): Baseline de anomal√≠as
- LSTM (15%): Contexto temporal

## üìä Dataset

### Fuente Principal
**Credit Card Fraud Detection Dataset** (Kaggle)
- **Total de transacciones**: 284,807
- **Casos de fraude**: 492 (0.172%)
- **Features**: 30 (28 anonimizadas por PCA + Time + Amount)
- **Desbalance**: 577:1 (realista para industria)

### Features Originales
- `Time`: Segundos transcurridos desde primera transacci√≥n
- `V1-V28`: Componentes PCA an√≥nimos
- `Amount`: Monto de la transacci√≥n
- `Class`: 0 = Leg√≠timo, 1 = Fraude

### Feature Engineering (50+ caracter√≠sticas derivadas)

**Caracter√≠sticas temporales**:
- Hora del d√≠a, d√≠a de la semana, fin de semana
- Velocidad de transacciones (transacciones/hora)
- Gap temporal desde √∫ltima transacci√≥n

**Caracter√≠sticas de monto**:
- Log(amount), sqrt(amount)
- Desviaci√≥n del monto promedio del usuario
- Ratio respecto al percentil 95

**Caracter√≠sticas de usuario**:
- N√∫mero de transacciones en √∫ltima hora/d√≠a
- Monto total en ventana temporal
- Frecuencia de merchant_category

**Caracter√≠sticas de anomal√≠a**:
- Distancia a centroide del cluster
- Local Outlier Factor (LOF)
- Isolation score

### Preparaci√≥n de Datos

**Divisi√≥n estratificada**:
- Train: 70% (mantiene ratio 0.172%)
- Validation: 15%
- Test: 15%

**T√©cnicas de balanceo**:
- SMOTE para oversampling de clase minoritaria
- Random undersampling de clase mayoritaria
- Ratio final training: 1:5

## üöÄ Instalaci√≥n y Configuraci√≥n

### Requisitos Previos
- Python 3.11+
- Node.js 18+
- Docker y Docker Compose
- Git

### Instalaci√≥n R√°pida
```bash
# Clonar repositorio
git clone https://github.com/tu-usuario/fraud-detection-system.git
cd fraud-detection-system

# Backend
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt

# Frontend
cd ../frontend
npm install

# Base de datos SQLite (se crea autom√°ticamente)
cd ../backend
python -m app.models.database

# Entrenar modelos (opcional, incluye modelos pre-entrenados)
python ml_pipeline/train.py
```

### Ejecuci√≥n con Docker
```bash
# Construir y levantar todos los servicios
docker-compose up --build

# Acceder a:
# - Frontend: http://localhost:3000
# - Backend API: http://localhost:8000
# - API Docs: http://localhost:8000/docs
# - MLflow: http://localhost:5000
```

### Ejecuci√≥n en Desarrollo

**Backend**:
```bash
cd backend
uvicorn app.main:app --reload --port 8000
```

**Frontend**:
```bash
cd frontend
npm run dev
```

## üìñ Uso del Sistema

### API Endpoints Principales

**Predicci√≥n de Fraude**:
```bash
POST /api/v1/predict
Content-Type: application/json

{
  "transaction_id": "TXN123456",
  "amount": 150.50,
  "merchant_category": "online_retail",
  "features": {...}
}

Response:
{
  "is_fraud": true,
  "confidence": 0.87,
  "fraud_probability": 0.92,
  "explanation": {
    "top_features": [
      {"feature": "amount_deviation", "contribution": 0.35},
      {"feature": "transaction_velocity", "contribution": 0.28}
    ],
    "shap_values": {...}
  }
}
```

**An√°lisis de Transacci√≥n**:
```bash
GET /api/v1/transactions/{transaction_id}/explain
```

**M√©tricas del Modelo**:
```bash
GET /api/v1/analytics/model-performance
```

### Dashboard Interactivo

**Funcionalidades**:
1. **Monitoreo en Tiempo Real**: Stream de transacciones con colores seg√∫n riesgo
2. **Visualizaci√≥n de Explicaciones**: Gr√°ficos SHAP interactivos por transacci√≥n
3. **M√©tricas de Performance**: Precision, Recall, F1, curvas ROC/PR
4. **Hist√≥rico de Alertas**: Tabla filtrable con exportaci√≥n
5. **An√°lisis de Tendencias**: Gr√°ficos temporales de fraude

## üß™ Testing

### Backend
```bash
# Tests unitarios
pytest tests/unit -v

# Tests de integraci√≥n
pytest tests/integration -v

# Coverage
pytest --cov=app --cov-report=html
```

### Frontend
```bash
# Tests unitarios
npm run test

# Tests E2E
npm run test:e2e
```

## üìà Roadmap de Desarrollo

### Fase 1: Fundaci√≥n (Semanas 1-2) ‚úÖ
- [x] Setup del proyecto y estructura
- [x] Configuraci√≥n de entorno (Docker, venv)
- [x] EDA completo del dataset
- [x] An√°lisis de desbalance y estrategias

### Fase 2: Feature Engineering (Semanas 2-3)
- [ ] Implementar pipeline de feature engineering
- [ ] Crear 50+ caracter√≠sticas derivadas
- [ ] Feature selection con importance
- [ ] Validaci√≥n de features

### Fase 3: Modelos ML/DL (Semanas 3-6)
- [ ] Implementar y entrenar Isolation Forest
- [ ] Desarrollar XGBoost con hyperparameter tuning
- [ ] Construir y entrenar Autoencoder
- [ ] Implementar LSTM para an√°lisis secuencial
- [ ] Desarrollar sistema de ensemble voting
- [ ] Optimizar threshold con curva ROC

### Fase 4: Explicabilidad (Semanas 6-7)
- [ ] Integrar SHAP para feature importance
- [ ] Implementar LIME para explicaciones locales
- [ ] Crear visualizaciones interactivas
- [ ] Desarrollar servicio de explicabilidad

### Fase 5: Backend API (Semanas 7-9)
- [ ] Desarrollar endpoints FastAPI
- [ ] Implementar servicios de negocio
- [ ] Agregar WebSockets para alertas
- [ ] Integrar modelos con API
- [ ] Tests unitarios e integraci√≥n

### Fase 6: Frontend (Semanas 9-11)
- [ ] Configurar React + TypeScript + Vite
- [ ] Desarrollar componentes de dashboard
- [ ] Implementar visualizaciones con Recharts
- [ ] Integrar con backend API
- [ ] Responsive design
- [ ] Tests de componentes

### Fase 7: DevOps y Deploy (Semanas 11-12)
- [ ] Dockerizar backend y frontend
- [ ] Configurar Docker Compose
- [ ] Implementar CI/CD con GitHub Actions
- [ ] Agregar pre-commit hooks
- [ ] Documentaci√≥n completa (README, API docs)
- [ ] Video demo del proyecto

### Futuras Mejoras (Post-MVP)
- [ ] Migraci√≥n a PostgreSQL
- [ ] Deploy en AWS/Azure/GCP
- [ ] Implementar autenticaci√≥n (JWT)
- [ ] Agregar rate limiting
- [ ] A/B testing framework para modelos
- [ ] Model drift detection autom√°tico
- [ ] Integraci√≥n con Kafka para streaming
- [ ] Dashboard de MLOps con Grafana

## üìä M√©tricas Esperadas

### Performance de Modelos (Dataset de Prueba)

| Modelo | Precision | Recall | F1-Score | AUC-ROC |
|--------|-----------|--------|----------|---------|
| Isolation Forest | 0.78 | 0.71 | 0.74 | 0.85 |
| XGBoost | 0.92 | 0.87 | 0.89 | 0.96 |
| Autoencoder | 0.81 | 0.83 | 0.82 | 0.89 |
| LSTM | 0.85 | 0.79 | 0.82 | 0.91 |
| **Ensemble** | **0.94** | **0.91** | **0.92** | **0.97** |

### KPIs del Sistema
- **Latencia de predicci√≥n**: <100ms (p95)
- **Throughput**: >1000 transacciones/segundo
- **Falsos positivos**: <5% (cr√≠tico para UX)
- **Disponibilidad**: 99.9% (SLA objetivo)

## ü§ù Contribuciones

Este es un proyecto de portafolio personal, pero las sugerencias son bienvenidas:

1. Fork el repositorio
2. Crea una rama (`git checkout -b feature/mejora`)
3. Commit cambios (`git commit -m 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/mejora`)
5. Abre un Pull Request

## üìù Licencia

MIT License - ver archivo [LICENSE](LICENSE) para detalles

## üë§ Autor

**Jhon Alexander Garc√≠a**

- LinkedIn: [tu-perfil](https://linkedin.com/in/tu-perfil)
- GitHub: [@tu-usuario](https://github.com/tu-usuario)
- Email: tu.email@ejemplo.com

---

## üéì Contexto Acad√©mico

Este proyecto fue desarrollado aplicando conocimientos adquiridos en Maestr√≠a en Inteligencia Artificial, enfoc√°ndose en:

- Aplicaci√≥n pr√°ctica de algoritmos de ML/DL en problemas reales
- Arquitectura de sistemas de IA en producci√≥n
- Explicabilidad y √©tica en modelos de IA
- Ingenier√≠a de software y mejores pr√°cticas
- DevOps y MLOps para sistemas de IA

## üìö Referencias

- [SHAP: A Unified Approach to Interpreting Model Predictions](https://arxiv.org/abs/1705.07874)
- [XGBoost: A Scalable Tree Boosting System](https://arxiv.org/abs/1603.02754)
- [Isolation Forest Algorithm](https://ieeexplore.ieee.org/document/4781136)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Credit Card Fraud Detection Dataset](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)

---

**Nota**: Este proyecto est√° en desarrollo activo. El c√≥digo y la documentaci√≥n se actualizan regularmente seg√∫n avance el roadmap.
